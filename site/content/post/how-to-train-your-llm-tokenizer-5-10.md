---
title: "How to train your LLM: Tokenizer (5/10)"
date: 2023-06-01T21:39:59.838Z
description: We'll focus on training a tokenizer for your Language Learning
  Model (LLM) in Python. Tokenization is the process of splitting text into
  individual tokens or words, enabling effective language analysis. We'll
  explore various tokenization approaches and provide practical examples and
  Python code snippets to guide you through training and using a tokenizer in
  your LLM. By the end of this part, you'll have the knowledge and tools to
  train a tokenizer that aligns with your LLM's requirements, enhancing its
  language processing capabilities.
image: img/830f839d688141e38b64fd1b4c53b9f6.png
---
* T﻿okenizers are made up of an algorithm and vocabulary
* M﻿any standard tokenizers are available from Hugging Face
* Train our own custom vocabulary from the underlying training data